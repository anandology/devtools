# Firecracker Sandbox - Design Notes

This is initial design document and some of the features may have evolved from this.

## Goal
Simple script to start/stop a Firecracker VM for AI agent development.

## User Experience

```bash
# First, extract vms.zip to your home directory, resulting in ~/vms/

# 1. One-time system setup (creates network bridge)
sudo ~/vms/setup.sh

# 2. Create a new VM instance (builds images, sets up dedicated TAP device)
sudo ~/vms/vm.sh create claude --template ubuntu-24.04

# 3. Daily use: Start, Stop, SSH (no sudo required after creation)
~/vms/vm.sh up claude
~/vms/vm.sh ssh claude
~/vms/vm.sh down claude
~/vms/vm.sh status claude
~/vms/vm.sh list            # List all created VMs

# 4. Destroy a VM instance (removes files, deletes TAP device)
sudo ~/vms/vm.sh destroy claude

# 5. One-time system cleanup (removes network bridge)
sudo ~/vms/cleanup.sh
```

## Architecture Decision: Modular Scripts for Lifecycle Management

The entire sandbox environment will be distributed as a `vms.zip` file, extracted to `~/vms/`. This top-level directory will contain global setup/cleanup scripts and a consolidated `vm.sh` script as the primary interface for VM lifecycle management.

```bash
# Example VM config: ~/vms/vms/claude/config.sh (automatically generated by 'vm.sh create')
# === CONFIG ===
NAME="claude"
GUEST_IP="172.16.0.2"    # Unique IP per sandbox (.2, .3, .4, etc.)
TAP_NAME="tap-claude"    # Dedicated TAP device name

CPUS=4
MEMORY=8192
ROOTFS_SIZE="8G"
HOME_SIZE="20G"

USERNAME="anand"
SSH_KEY_PATH="~/.ssh/id_ed25519.pub"
# SSH_KEY_URL="https://github.com/anandology.keys"

UBUNTU_VERSION="24.04"

PACKAGES="podman postgresql tmux"

NIX_PACKAGES=\
   go_1_24  \
   node

```

**Multiple sandboxes example:**
Each sandbox's `config.sh` (under `~/vms/vms/<name>/`) would define its unique properties:
```bash
# ~/vms/vms/claude/config.sh
NAME="claude"                 # ~/vms/vms/postgres/config.sh
GUEST_IP="172.16.0.2"         NAME="postgres"
TAP_NAME="tap-claude"         GUEST_IP="172.16.0.3"
CPUS=4                        TAP_NAME="tap-postgres"
MEMORY=8192                   CPUS=2
...                           MEMORY=4096
                              ...
```

---

## Critical Review & Gaps

### 1. Image Storage Location

**Options:**
- (A) Next to script: `./.claude-sandbox/`
- (B) Centralized: `~/.local/share/firecracker-sandbox/<name>/`
- (C) Hybrid: shared kernel, per-sandbox rootfs/home

**Analysis:**
- Option A: Simple, self-contained, but 30GB+ per sandbox
- Option B: Can share kernel across sandboxes, cleaner home directory
- Option C: Most efficient but complex

**Decision:** Go with (B) - centralized storage
- `~/.local/share/firecracker-sandbox/kernels/vmlinux-6.1` (shared)
- `~/.local/share/firecracker-sandbox/<name>/rootfs.ext4`
- `~/.local/share/firecracker-sandbox/<name>/home.ext4`
- `~/.local/share/firecracker-sandbox/<name>/vm.pid`

### 2. Multi-VM Networking & Sudo Usage

**Problem:** Reconcile VM network management (which requires `sudo`) with the goal of `sudo`-less daily VM operations.
**Constraint:** `sudo` is acceptable for one-time system setup and per-VM creation/destruction. `vm.sh up` and `vm.sh down` must be `sudo`-less.

**Decision:**
*   Global `setup.sh` manages the network bridge (`br-firecracker`).
*   `vm.sh create` handles privileged, one-time per-VM setup (TAP device creation).
*   `vm.sh destroy` handles privileged, one-time per-VM cleanup (TAP device deletion).

**How it works:**
1.  **`setup.sh` (one-time, `sudo`):** Creates bridge `br-firecracker` with IP 172.16.0.1/24, NAT rules. This is a system-wide component.
2.  **`vm.sh create <name>` (one-time per VM, `sudo`):**
    *   Creates a dedicated, persistent TAP device for the VM (e.g., `tap-claude`).
    *   Assigns ownership of this TAP device to the user who *invoked `sudo`* (using `$SUDO_USER`). This is critical. Example: `ip tuntap add tap-$NAME mode tap user "$SUDO_USER"`.
    *   Attaches this TAP device to `br-firecracker` and brings it up.
    *   Builds VM rootfs/home images and sets their ownership to `$SUDO_USER`.
    *   This ensures that all VM-specific network resources are established and owned by the regular user.
3.  **`vm.sh up <name>` (daily operation, no `sudo`):** The Firecracker process, running as the regular user, uses its pre-configured, user-owned TAP device (`tap-$NAME`). No `sudo` is required.
4.  **`vm.sh down <name>` (daily operation, no `sudo`):** Stops the Firecracker process. The dedicated TAP device remains active and owned by the user. No `sudo` is required.
5.  **`vm.sh destroy <name>` (one-time per VM, `sudo`):**
    *   Deletes the dedicated TAP device (`tap-$NAME`). This requires `sudo`.
    *   Removes the VM's files and state.
6.  **`cleanup.sh` (one-time, `sudo`):** Removes the `br-firecracker` bridge.

**IP allocation:** User specifies GUEST_IP in config. Framework validates no conflict.

**Conflict detection:**
```bash
# Check state files for running VMs with same IP
for vm_dir in ~/vms/vms/*/; do
    if [[ -f "$vm_dir/vm.pid" ]] && kill -0 "$(cat "$vm_dir/vm.pid")" 2>/dev/null; then
        running_ip=$(cat "$vm_dir/guest_ip")
        if [[ "$running_ip" == "$GUEST_IP" ]]; then
            echo "Error: $GUEST_IP already in use by $(basename "$vm_dir")"
            exit 1
        fi
    fi
done
```

### 3. Docker Dependency for Building

**Problem:** Need Docker to build Ubuntu 24.04 rootfs from 22.04 host.

**Options:**
- (A) Require Docker (current plan)
- (B) Support Docker or Podman
- (C) Provide pre-built base images (download instead of build)

**Decision:** Option B - support both
```bash
CONTAINER_CMD="${CONTAINER_CMD:-$(command -v docker || command -v podman)}"
```

### 4. SSH Key - Network Dependency

**Problem:** `github:username` requires network access.

**Solution:**
- Fetch once, cache in state directory
- Reuse cached key on subsequent builds
- Fail clearly if network unavailable and no cache

### 5. Config Changes After First Boot

**Problem:** If user changes PACKAGES in config after first boot, changes aren't applied.

**Options:**
- (A) Ignore - user must `rebuild`
- (B) Track config hash, detect changes, re-run setup
- (C) Always check packages on `up`

**Decision:** Option A for simplicity
- Document: "Change packages? Run `./sandbox.sh rebuild`"
- Keep first boot fast on subsequent starts

### 6. Error Recovery

**Gaps identified:**
- Build fails mid-way: partial state left behind
- VM crashes: stale PID file
- Network setup fails: unclear state

**Solutions:**
- Check PID file validity (process actually running?)
- Cleanup on build failure
- Clear error messages with recovery steps

### 7. Framework Distribution

**Options:**
- (A) Git clone this repo, source relative path
- (B) Install to /opt or ~/.local
- (C) Download on demand (curl | bash style)

**Decision:** Option A for now (it's in devtools repo)
```bash
source "$(dirname "$0")/sandbox.sh"
```

---

## Design for v1

### Capabilities
1. Multiple VMs simultaneously (bridge networking)
2. User-assigned IPs: 172.16.0.2, .3, .4, etc.
3. Shared kernel, per-VM rootfs and home volumes
4. Framework lives in devtools repo (source relative path)

### Constraints (intentional limitations)
1. Config changes require explicit rebuild
2. IP conflicts detected but not auto-assigned (user picks IP)

### Directory Structure
```
~/vms/                     # Root directory from vms.zip extraction
├── README.md              # Documentation for users
├── setup.sh               # Global one-time system setup (sudo)
├── cleanup.sh             # Global one-time system cleanup (sudo)
├── vm.sh                  # Main CLI for VM management (create, up, down, etc.)
├── lib/                   # Helper functions sourced by vm.sh, setup.sh, cleanup.sh
│   ├── common.sh          # Common utilities
│   ├── network_global.sh  # Bridge setup/cleanup logic
│   ├── vm_creation.sh     # Logic for vm.sh create
│   └── vm_lifecycle.sh    # Logic for vm.sh up/down/status
└── templates/             # Base images/configs for new VMs
│   └── ubuntu-24.04/
│       ├── config.sh.tmpl # Template for VM-specific config
│       ├── rootfs.ext4    # Base root filesystem (downloaded/built once)
│       └── ...
└── vms/                   # Contains all active/created VM instances
    └── claude/            # Per-VM instance directory
        ├── config.sh      # VM-specific configuration
        ├── rootfs.ext4    # Dedicated root filesystem (copy of template, then modified)
        ├── home.ext4      # Dedicated home filesystem
        ├── ssh_key.pub    # Cached SSH key
        ├── guest_ip       # e.g., "172.16.0.2"
        ├── tap_name       # e.g., "tap-claude"
        ├── vm.pid
        ├── vm.sock
        └── .first-boot-done
```

### Command Flow (Revised for the `~/vms/` structure)

**Global Scripts (run from `~/vms/`):**

**`setup.sh` command (one-time system setup, `sudo` required):**
```bash
# ~/vms/setup.sh
# 1. Check prerequisites (KVM, Docker/Podman).
# 2. Create bridge `br-firecracker`, add IP 172.16.0.1/24.
# 3. Set up NAT rules (iptables).
# 4. (Optional) Persist bridge setup with systemd service.
# 5. Print success message.
```

**`cleanup.sh` command (one-time system cleanup, `sudo` required):**
```bash
# ~/vms/cleanup.sh
# 1. Iterate through all created VMs (`~/vms/vms/*`) and run `vm.sh down` for any running VM.
# 2. Iterate through all created VMs and run `vm.sh destroy` (requires sudo) to clean up all TAP devices.
# 3. Remove `br-firecracker` bridge and associated NAT rules.
# 4. (Optional) Remove systemd persistence.
# 5. Print success message.
```

**VM Management Scripts (run via `~/vms/vm.sh <command> <name>`):**

**`vm.sh create <name> [--template <tmpl>]` command (per VM setup, `sudo` required):**
```bash
# ~/vms/vm.sh create claude --template ubuntu-24.04
# 1. Validate VM name and template.
# 2. Create VM instance directory: `~/vms/vms/<name>/`.
# 3. Build/download base images: rootfs.ext4, vmlinux.
# 4. Create home volume (home.ext4).
# 5. SSH Key Fetch: fetch (GitHub + local + caching).
# 6. Generate VM-specific config.sh.
# 7. Privileged Network Setup (requires sudo):
#    - Create dedicated TAP device (`tap-<name>`) with `user $SUDO_USER`.
#    - Attach `tap-<name>` to `br-firecracker`, bring up.
# 8. Set ownership of `~/vms/vms/<name>/` and all its contents to `$SUDO_USER`.
# 9. Print success message.
```
*Note: `$SUDO_USER` refers to the original user who invoked `sudo`.*

**`vm.sh up <name>` command (start VM, no `sudo`):**
```bash
# ~/vms/vm.sh up claude
# 1. Load VM config (`~/vms/vms/<name>/config.sh`).
# 2. Check if VM is already running → skip start if yes.
# 3. Check GUEST_IP not in use by another VM.
# 4. Start Firecracker VM (background) using its pre-configured rootfs, home, and dedicated, user-owned TAP device (`tap-<name>`).
# 5. Save state (PID, IP, socket path).
# 6. Wait for SSH to become available.
# 7. If first boot (`.first-boot-done` marker missing):
#    - Install Nix + packages via SSH.
#    - Clone repos via SSH.
#    - Create marker `.first-boot-done`.
# 8. Print ready message with SSH command.
```

**`vm.sh down <name>` command (stop VM, no `sudo`):**
```bash
# ~/vms/vm.sh down claude
# 1. Load VM config.
# 2. Check if running (PID file valid).
# 3. SSH: sudo poweroff (graceful shutdown inside VM).
# 4. Wait for process exit (timeout 30s).
# 5. Cleanup: remove socket file. The dedicated TAP device remains active.
# 6. Clear state files (PID).
```

**`vm.sh ssh <name>` command (connect to VM, no `sudo`):**
```bash
# ~/vms/vm.sh ssh claude
# 1. Load VM config.
# 2. Check if VM is running.
# 3. exec ssh -i <key> <user>@<GUEST_IP> (using GUEST_IP from state).
```

**`vm.sh status <name>` command (check VM state, no `sudo`):**
```bash
# ~/vms/vm.sh status claude
# 1. Load VM config.
# 2. Check PID file validity.
# 3. Show: running/stopped, IP, uptime.
# 4. If running, show resource usage.
```

**`vm.sh list` command (shows all VMs, no `sudo`):**
```bash
# ~/vms/vm.sh list
# 1. Scan `~/vms/vms/*/`.
# 2. For each, load config and check if running.
# 3. Print table: NAME, IP, STATUS, UPTIME.
```

**`vm.sh destroy <name>` command (per VM cleanup, `sudo` required):**
```bash
# ~/vms/vm.sh destroy claude
# 1. Load VM config.
# 2. Run `vm.sh down <name>` if running.
# 3. Privileged Network Cleanup (requires sudo):
#    - Remove the dedicated TAP device (`tap-<name>`).
# 4. Delete VM files: rootfs, home volume, state files, config.sh, etc. (`~/vms/vms/<name>/`).
# 5. Print success message.
```

**`rebuild` functionality:** This would likely be a sequence executed by the user: `sudo ~/vms/vm.sh destroy <name>`, then `sudo ~/vms/vm.sh create <name>`. Or it could be a subcommand: `sudo ~/vms/vm.sh rebuild <name>` which orchestrates the destroy/create.

---

## Network Setup Details

### Bridge Setup (one-time, requires sudo)

```bash
# Create bridge
sudo ip link add br-firecracker type bridge
sudo ip addr add 172.16.0.1/24 dev br-firecracker
sudo ip link set br-firecracker up

# Enable IP forwarding
sudo sysctl -w net.ipv4.ip_forward=1

# NAT rules
HOST_IFACE=$(ip route | grep default | awk '{print $5}')
sudo iptables -t nat -A POSTROUTING -o "$HOST_IFACE" -j MASQUERADE
sudo iptables -A FORWARD -i br-firecracker -o "$HOST_IFACE" -j ACCEPT
sudo iptables -A FORWARD -i "$HOST_IFACE" -o br-firecracker -m state --state RELATED,ESTABLISHED -j ACCEPT

# Persist with systemd service (like existing setup-tap.sh)
```

### Per-VM TAP Setup (Managed by `vm.sh create`/`destroy`)

```bash
# This setup happens as part of 'sudo ~/vms/vm.sh create <name>'
# 1. Create TAP for this VM, assign ownership to the calling user:
sudo ip tuntap add tap-$NAME mode tap user "$SUDO_USER"
# 2. Attach it to the bridge:
sudo ip link set tap-$NAME master br-firecracker
# 3. Bring it up:
sudo ip link set tap-$NAME up

# This TAP device persists as long as the VM exists (until 'sudo ~/vms/vm.sh destroy <name>')
# It is deleted as part of 'sudo ~/vms/vm.sh destroy <name>':
# sudo ip link delete tap-$NAME
```

### VM Network Config (inside rootfs)

```
# /etc/systemd/network/eth0.network
[Match]
Name=eth0

[Network]
Address=<GUEST_IP>/24
Gateway=172.16.0.1
DNS=8.8.8.8
```

---

## Resolved Questions

1. **Should `up` be blocking or return immediately?**
   - Decision: Blocking, shows progress, prints ready message with SSH command

2. **Logs location?**
   - VM console: `~/.local/share/firecracker-sandbox/<name>/console.log`
   - Setup log: `~/.local/share/firecracker-sandbox/<name>/setup.log`

3. **How to handle sudo?**
   - `setup.sh`: Global system setup (bridge creation, NAT rules) requires `sudo`.
   - `vm.sh create <name>`: Per-VM creation (TAP device creation, attachment, ownership) requires `sudo`.
   - `vm.sh up <name>` / `vm.sh down <name>`: Daily VM operations run without `sudo`.
   - `vm.sh destroy <name>`: Per-VM destruction (TAP device deletion) requires `sudo`.
   - `cleanup.sh`: Global system cleanup (bridge removal, NAT rules) requires `sudo`.

4. **Multi-VM support?**
   - Yes, via bridge networking with user-assigned IPs.
   - User assigns unique GUEST_IP per sandbox.
   - Framework detects conflicts (in `start.sh`).
   - **Why not user-mode networking (`slirp4netns`) for multiple VMs?**
     - While it avoids `sudo` for network setup, it creates isolated virtual networks for each VM.
     - This significantly complicates inter-VM communication (VM1 cannot directly talk to VM2 using `GUEST_IP`).
     - Host-to-VM communication requires port forwarding (e.g., `ssh -p 2222 localhost` instead of `ssh user@GUEST_IP`), hindering the desired UX.
     - Performance is generally lower due to multiple layers of user-space processing (`slirp-in-slirp` if Podman is used inside the VM).
     - Debugging network issues becomes much harder.
     - The bridge-based approach, with one-time `sudo` setup for persistent, user-owned TAP devices, offers a more robust, performant, and manageable solution for interacting multi-VM environments.

---

## Task Breakdown (Revised)

### Epic: firecracker-sandbox

**Overall Goal:** No `sudo` for daily `start.sh`, `stop.sh`, `ssh.sh` operations. `sudo` is accepted for one-time `build.sh` phase.

**Feature 1: Framework Core**
- Task 1.1: Create framework scripts (`build.sh`, `start.sh`, `stop.sh`, `ssh.sh`, `status.sh`, `list.sh`, `destroy.sh`).
- Task 1.2: Implement centralized config loading (e.g., each VM's `config.sh` sources main framework libs).
- Task 1.3: State management (save/load PID, IP, dedicated TAP name, socket path).

**Feature 2: Prerequisites & Network Setup**
- Task 2.1: Implement prerequisite checker (KVM, Docker/Podman).
- Task 2.2: `build.sh` includes bridge network setup (br-firecracker, NAT rules, systemd persistence) (requires `sudo`).
- Task 2.3: `build.sh` includes dedicated per-VM TAP creation with `user $USER` and attachment to bridge (requires `sudo`).
- Task 2.4: IP conflict detection in `start.sh`.

**Feature 3: Image Building (part of `build.sh`)**
- Task 3.1: Kernel downloader (shared location).
- Task 3.2: Docker/Podman-based rootfs builder for Ubuntu 24.04.
- Task 3.3: Home volume creation (separate from rootfs).
- Task 3.4: SSH key fetcher (GitHub + local + caching).

**Feature 4: VM Lifecycle**
- Task 4.1: `start.sh` implements VM start (background, with assigned dedicated TAP and IP) (no `sudo`).
- Task 4.2: `stop.sh` implements VM stop (graceful shutdown, socket cleanup) (no `sudo`). The dedicated TAP device remains.
- Task 4.3: `ssh.sh` helper (uses GUEST_IP from state) (no `sudo`).
- Task 4.4: `status.sh` command (no `sudo`).
- Task 4.5: `list.sh` command (show all VMs) (no `sudo`).

**Feature 5: First-Boot Automation (part of `start.sh`)**
- Task 5.1: Wait for SSH ready.
- Task 5.2: Package installation via SSH (Nix + packages).
- Task 5.3: Repo cloning via SSH.

**Feature 6: Polish**
- Task 6.1: `destroy.sh` for removing VM data (rootfs, home, state). (Optional: `sudo` for TAP device removal).
- Task 6.2: Implement `rebuild` functionality (likely a sequence of `stop.sh`, remove `rootfs.ext4`, then `start.sh`).
- Task 6.3: Example `config.sh` for common sandbox types.
- Task 6.4: Documentation (including `sudo` requirements and usage).

---

## Alternatives Considered

### Why not use Vagrant?
- Heavy, requires VirtualBox/libvirt
- Firecracker is lighter, faster boot

### Why not use Docker?
- Not a real VM, shared kernel
- Can't run systemd properly
- Security isolation weaker

### Why not use ignite (Weaveworks)?
- Deprecated
- Uses containerd, adds complexity
- We want simpler

### Why not use LXC/LXD?
- Containers, not VMs
- Shared kernel security concerns for untrusted code
